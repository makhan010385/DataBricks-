{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLC1VKVS0lMx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "PCYdsOCY0l_6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "cyUu7TXd0mDz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Ah22ndgU1JnB",
        "outputId": "c92d24fb-14f5-49ee-c915-64fc99073821"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e2a98fc7210>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7c4e257983b8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hYz9ZVB60mOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IfapJW--0mRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zjtOr54o0mVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LocalSparkExample\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 1: Use RAW GitHub CSV link\n",
        "url = \"https://raw.githubusercontent.com/makhan010385/DataBricks-/main/merged_final.csv\"\n",
        "\n",
        "# Step 2: Load CSV into Pandas DataFrame\n",
        "pdf = pd.read_csv(url)\n",
        "\n",
        "# Step 3: Convert Pandas → Spark DataFrame\n",
        "df = spark.createDataFrame(pdf)\n",
        "\n",
        "# Step 4: Show results\n",
        "df.show(5)\n",
        "df.printSchema()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImgPOOPK1EJ7",
        "outputId": "e789d8c2-74f4-4d06-ede9-b9009672ffac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+\n",
            "|Unnamed: 0|          author|           statement|         source|         date|     target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+----------+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+\n",
            "|         0|Marta Campabadal|“Netflix estrenó ...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE| NaN|\n",
            "|         1|  Louis Jacobson|Says that under h...|      Joe Biden|June 29, 2023|mostly-true|        REAL|              1| NaN|REAL|\n",
            "|         2|    Jeff Cercone|\"ONU ordena despe...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE| NaN|\n",
            "|         3|      Sara Swann|NASA warns of “in...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE| NaN|\n",
            "|         4|    Jeff Cercone|Video suggests CO...|Instagram posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE| NaN|\n",
            "+----------+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- Unnamed: 0: long (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            " |-- statement: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- target: string (nullable = true)\n",
            " |-- BinaryTarget: string (nullable = true)\n",
            " |-- BinaryNumTarget: long (nullable = true)\n",
            " |-- Fake: string (nullable = true)\n",
            " |-- Real: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Display the summary statistics"
      ],
      "metadata": {
        "id": "V1K6dIVA1ov8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the summary statistics of the data\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fTix4ro1sfq",
        "outputId": "79209885-41b9-443a-a938-2f50aa7aac0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------+--------------------+--------------------+--------------------+-------------+-------------+-------------------+-------------------+--------------------+\n",
            "|summary|               _c0|         _c1|                 _c2|                 _c3|                 _c4|          _c5|          _c6|                _c7|                _c8|                 _c9|\n",
            "+-------+------------------+------------+--------------------+--------------------+--------------------+-------------+-------------+-------------------+-------------------+--------------------+\n",
            "|  count|              6001|        6001|                6001|                6001|                6001|         6001|         6001|               6001|               5253|                 573|\n",
            "|   mean|            2999.5|        NULL|                NULL|                 0.0|                 0.0|          2.0|         NULL|0.12988826815642457| 0.4090909090909091| 0.16666666666666666|\n",
            "| stddev|1732.1951391226105|        NULL|                NULL|                 0.0|                 0.0|          0.0|         NULL|0.33620981554956725|0.49306884216799096|  0.3752933125204009|\n",
            "|    min|                 0|Aarón Torres|\"\"\"$1 of every $3...| (Wisconsin Repub...| Honduras y El Sa...|            2| DUI offenses|         DEA agents|      and so on.\"\"\"| and even 2nd deg...|\n",
            "|    max|        Unnamed: 0|      author|“‘The View’ settl...|              source|     • September 26,|• February 3,|   pants-fire|         pants-fire|        mostly-true|                Real|\n",
            "+-------+------------------+------------+--------------------+--------------------+--------------------+-------------+-------------+-------------------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert Spark Dataframe to Pandas"
      ],
      "metadata": {
        "id": "6kHr1xh510au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pandas_df =df.toPandas()\n",
        "pandas_df.head()\n",
        "pandas_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzdfyyai2Ejw",
        "outputId": "5b3509df-6e21-47a8-be6d-8be90ccc22da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Unnamed: 0       6000 non-null   int32 \n",
            " 1   author           6000 non-null   object\n",
            " 2   statement        6000 non-null   object\n",
            " 3   source           6000 non-null   object\n",
            " 4   date             6000 non-null   object\n",
            " 5   target           6000 non-null   object\n",
            " 6   BinaryTarget     6000 non-null   object\n",
            " 7   BinaryNumTarget  6000 non-null   object\n",
            " 8   Fake             5252 non-null   object\n",
            " 9   Real             572 non-null    object\n",
            "dtypes: int32(1), object(9)\n",
            "memory usage: 445.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we can use pandas operations on the pandas_df dataframe.\n",
        "\n",
        "##Data Transformation\n",
        "##Select specific columns"
      ],
      "metadata": {
        "id": "yEvPGfmZ2LRj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UsjZRgkjT1Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select specific columns\n",
        "df.select(\"Unnamed: 0\", \"BinaryNumTarget\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRm33W4u2QUs",
        "outputId": "be5b99b2-2b8f-404f-b487-9b7ea5fb7dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------------+\n",
            "|Unnamed: 0|BinaryNumTarget|\n",
            "+----------+---------------+\n",
            "|         0|              0|\n",
            "|         1|              1|\n",
            "|         2|              0|\n",
            "|         3|              0|\n",
            "|         4|              0|\n",
            "+----------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rename a column"
      ],
      "metadata": {
        "id": "FTzzf1Z52bV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed =df.withColumnRenamed(\"Unnamed: 0\", \"id\")\n",
        "df_renamed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuv2e6113Jl_",
        "outputId": "72647476-26a6-418b-f577-9cc205e50b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+\n",
            "| id|          author|           statement|         source|         date|     target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+\n",
            "|  0|Marta Campabadal|“Netflix estrenó ...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  1|  Louis Jacobson|Says that under h...|      Joe Biden|June 29, 2023|mostly-true|        REAL|              1|NULL|REAL|\n",
            "|  2|    Jeff Cercone|\"\"\"ONU ordena des...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  3|      Sara Swann|NASA warns of “in...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  4|    Jeff Cercone|Video suggests CO...|Instagram posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "+---+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Filter data based on a condition"
      ],
      "metadata": {
        "id": "qIW7KXPx3TtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data based on a condition\n",
        "df_renamed.filter(df_renamed.id > 10).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZr2_ven3Ww8",
        "outputId": "7c4e014f-e3fa-4fc0-f016-493c683dfb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+--------------------+---------------+-------------+----------+------------+---------------+----+----+\n",
            "| id|          author|           statement|         source|         date|    target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+----------------+--------------------+---------------+-------------+----------+------------+---------------+----+----+\n",
            "| 11|      Nuria Diaz|John F. Kennedy e...|Instagram posts|June 27, 2023|pants-fire|        FAKE|              0|FAKE|NULL|\n",
            "| 12|   Maria Briceño|\"\"\"Se filtran aud...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 13|Marta Campabadal|Fotos muestran ro...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 14|    Jeff Cercone|Audio is of “the ...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 15|   Maria Briceño|\"\"\"Imagenes de lo...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "+---+----------------+--------------------+---------------+-------------+----------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data based on a condition\n",
        "# We & opprator\n",
        "\n",
        "df_renamed.filter((df_renamed.id > 10)&(df_renamed.id < 20)).show(5)\n",
        "\n",
        "# With between ofpp\n",
        "\n",
        "df_renamed.filter(df_renamed.id.between(12,80)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LswKL1-tYGJx",
        "outputId": "abeef508-2b2f-43da-e060-514831c797fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+--------------------+---------------+-------------+----------+------------+---------------+----+----+\n",
            "| id|          author|           statement|         source|         date|    target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+----------------+--------------------+---------------+-------------+----------+------------+---------------+----+----+\n",
            "| 11|      Nuria Diaz|John F. Kennedy e...|Instagram posts|June 27, 2023|pants-fire|        FAKE|              0|FAKE|NULL|\n",
            "| 12|   Maria Briceño|\"\"\"Se filtran aud...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 13|Marta Campabadal|Fotos muestran ro...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 14|    Jeff Cercone|Audio is of “the ...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 15|   Maria Briceño|\"\"\"Imagenes de lo...| Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "+---+----------------+--------------------+---------------+-------------+----------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---+----------------+--------------------+--------------+-------------+------+------------+---------------+----+----+\n",
            "| id|          author|           statement|        source|         date|target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+----------------+--------------------+--------------+-------------+------+------------+---------------+----+----+\n",
            "| 12|   Maria Briceño|\"\"\"Se filtran aud...|Facebook posts|June 27, 2023| FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 13|Marta Campabadal|Fotos muestran ro...|Facebook posts|June 27, 2023| FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 14|    Jeff Cercone|Audio is of “the ...|Facebook posts|June 27, 2023| FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 15|   Maria Briceño|\"\"\"Imagenes de lo...|Facebook posts|June 27, 2023| FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 16| Loreben Tuquero|“Donald Trump cal...|Facebook posts|June 27, 2023| FALSE|        FAKE|              0|FAKE|NULL|\n",
            "+---+----------------+--------------------+--------------+-------------+------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWHsC5814KTE",
        "outputId": "7068e01c-7be1-4000-a629-e5011d170d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+--------------------+-------------+-----------+------------+---------------+----+----+\n",
            "| id|              author|           statement|              source|         date|     target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+--------------------+--------------------+--------------------+-------------+-----------+------------+---------------+----+----+\n",
            "|  0|    Marta Campabadal|“Netflix estrenó ...|      Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  1|      Louis Jacobson|Says that under h...|           Joe Biden|June 29, 2023|mostly-true|        REAL|              1|NULL|REAL|\n",
            "|  2|        Jeff Cercone|\"\"\"ONU ordena des...|      Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  3|          Sara Swann|NASA warns of “in...|      Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  4|        Jeff Cercone|Video suggests CO...|     Instagram posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  5|     Loreben Tuquero|“The day before 9...|     Instagram posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  6|       Tom Kertscher|Kevin McCarthy “a...|      Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|  7|Sofia Bliss-Carra...|Video showing som...|      Facebook posts|June 28, 2023| pants-fire|        FAKE|              0|FAKE|NULL|\n",
            "|  8|Sofia Bliss-Carra...|“Young Americans ...|     Vivek Ramaswamy|June 28, 2023|  half-true|        REAL|              1|NULL|REAL|\n",
            "|  9|         Grace Abels|\"Atrazine in the ...|Robert F. Kennedy...|June 28, 2023|      FALSE|        FAKE|              0|FAKE|NULL|\n",
            "+---+--------------------+--------------------+--------------------+-------------+-----------+------------+---------------+----+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Some more filtering examples:"
      ],
      "metadata": {
        "id": "UtgMvvB53g0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed.filter((df_renamed.author == 'Marta Campabadal')).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF_UMmCK30fU",
        "outputId": "ef9e173e-eac4-4c86-efd5-70edb245f515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+--------------------+--------------+-------------+----------+------------+---------------+----+----+\n",
            "| id|          author|           statement|        source|         date|    target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+----------------+--------------------+--------------+-------------+----------+------------+---------------+----+----+\n",
            "|  0|Marta Campabadal|“Netflix estrenó ...|Facebook posts|June 29, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 10|Marta Campabadal|Los cinco tripula...|Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 13|Marta Campabadal|Fotos muestran ro...|Facebook posts|June 27, 2023|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 59|Marta Campabadal|“Arma que EE.UU. ...|Facebook posts|   • June 20,|     FALSE|        FAKE|              0|FAKE|NULL|\n",
            "| 75|Marta Campabadal|\"\"\"Panico en Mosc...|Facebook posts|June 19, 2023|pants-fire|        FAKE|              0|FAKE|NULL|\n",
            "+---+----------------+--------------------+--------------+-------------+----------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed.filter((df_renamed.author.like('Louis%'))).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEQZAtwj5pYk",
        "outputId": "3e0eaa42-033c-4bf7-8572-5cab2a46e741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------+--------------------+--------------------+--------------+------------+------------+---------------+----+----+\n",
            "| id|        author|           statement|              source|          date|      target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+--------------+--------------------+--------------------+--------------+------------+------------+---------------+----+----+\n",
            "|  1|Louis Jacobson|Says that under h...|           Joe Biden| June 29, 2023| mostly-true|        REAL|              1|NULL|REAL|\n",
            "| 21|Louis Jacobson|“Median income in...|           Tim Scott| June 26, 2023|   half-true|        REAL|              1|NULL|REAL|\n",
            "|114|Louis Jacobson|“The family separ...|          Mike Pence|  June 8, 2023|       FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|131|Louis Jacobson|\"Having \"\"biologi...|         Nikki Haley|  June 6, 2023|       FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|139|Louis Jacobson|\"\"\"Every study ha...| “it puts more pe...|Kevin McCarthy|June 1, 2023| barely-true|           FAKE|   0|FAKE|\n",
            "+---+--------------+--------------------+--------------------+--------------+------------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed.filter((df_renamed.author.endswith('son'))).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbCFnyPc6HRt",
        "outputId": "0a705585-4d4f-4d3b-c7ad-eb60e916615c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------+--------------------+--------------------+--------------+------------+------------+---------------+----+----+\n",
            "| id|        author|           statement|              source|          date|      target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+---+--------------+--------------------+--------------------+--------------+------------+------------+---------------+----+----+\n",
            "|  1|Louis Jacobson|Says that under h...|           Joe Biden| June 29, 2023| mostly-true|        REAL|              1|NULL|REAL|\n",
            "| 21|Louis Jacobson|“Median income in...|           Tim Scott| June 26, 2023|   half-true|        REAL|              1|NULL|REAL|\n",
            "|114|Louis Jacobson|“The family separ...|          Mike Pence|  June 8, 2023|       FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|131|Louis Jacobson|\"Having \"\"biologi...|         Nikki Haley|  June 6, 2023|       FALSE|        FAKE|              0|FAKE|NULL|\n",
            "|139|Louis Jacobson|\"\"\"Every study ha...| “it puts more pe...|Kevin McCarthy|June 1, 2023| barely-true|           FAKE|   0|FAKE|\n",
            "+---+--------------+--------------------+--------------------+--------------+------------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TbKxMTAA8cQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Join DataFrames"
      ],
      "metadata": {
        "id": "Pk235qgx8Wgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting data using orderBy() method\n",
        "sorted_df = df.orderBy(\"author\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-vX6cSa8c7M",
        "outputId": "4d1b58ba-daaa-45d1-ce83-b59fbf813a8f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+--------------------+-----------------+--------------+-----------+------------+---------------+----+----+\n",
            "|Unnamed: 0|      author|           statement|           source|          date|     target|BinaryTarget|BinaryNumTarget|Fake|Real|\n",
            "+----------+------------+--------------------+-----------------+--------------+-----------+------------+---------------+----+----+\n",
            "|       327|Aarón Torres|“Fentanyl is the ...|      Greg Abbott|April 24, 2023|mostly-true|        REAL|              1| NaN|REAL|\n",
            "|      3426|Aarón Torres|When discussing e...|Brandon Creighton|March 30, 2023|  half-true|        REAL|              1| NaN| NaN|\n",
            "|       426|Aarón Torres|When discussing e...|Brandon Creighton|March 30, 2023|  half-true|        REAL|              1| NaN|REAL|\n",
            "|      3327|Aarón Torres|“Fentanyl is the ...|      Greg Abbott|April 24, 2023|mostly-true|        REAL|              1| NaN| NaN|\n",
            "|       469|Aarón Torres|\"Businesses large...|      Greg Abbott|March 20, 2023|  half-true|        REAL|              1| NaN|REAL|\n",
            "+----------+------------+--------------------+-----------------+--------------+-----------+------------+---------------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Count articles per author by sql"
      ],
      "metadata": {
        "id": "pjYlOXM49GCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"AggregationExample\").getOrCreate()\n",
        "\n",
        "# Load CSV\n",
        "df = spark.createDataFrame(pdf)\n",
        "\n",
        "# Group by Author and count\n",
        "df_agg = df.groupBy(\"author\").agg(\n",
        "    F.count(\"*\").alias(\"article_count\")\n",
        ")\n",
        "\n",
        "# Sort by highest count\n",
        "df_agg = df_agg.orderBy(F.desc(\"article_count\"))\n",
        "\n",
        "df_agg.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-o2zdnW9OCq",
        "outputId": "200f5a31-13b7-4111-ac08-9193d107951c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|           author|article_count|\n",
            "+-----------------+-------------+\n",
            "|   Ciara O'Rourke|         1732|\n",
            "|     Jeff Cercone|          372|\n",
            "|Gabrielle Settles|          340|\n",
            "|    Tom Kertscher|          304|\n",
            "|   Madison Czopek|          280|\n",
            "|      Andy Nguyen|          268|\n",
            "|   Louis Jacobson|          240|\n",
            "|  Loreben Tuquero|          228|\n",
            "|      Amy Sherman|          216|\n",
            "|       Sara Swann|          196|\n",
            "+-----------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Count distinct sources per author"
      ],
      "metadata": {
        "id": "CU0hxFXm9fw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"author\").agg(\n",
        "    F.countDistinct(\"source\").alias(\"unique_sources\")\n",
        ").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXPBYGCY9nQr",
        "outputId": "ebc4009c-7756-4fb1-9416-94ee64dd79bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+\n",
            "|         author|unique_sources|\n",
            "+---------------+--------------+\n",
            "|  Jon Greenberg|            15|\n",
            "|  Liam Halawith|             4|\n",
            "| Sydney Carruth|             1|\n",
            "|    Amy Sherman|            28|\n",
            "|   Warren Fiske|            15|\n",
            "|    Grace Abels|            10|\n",
            "|Faithlyn Graham|             1|\n",
            "|   Jill Terreri|            11|\n",
            "| Vanessa Swales|             7|\n",
            "|   Blake Farmer|             1|\n",
            "+---------------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multiple aggregations in one go"
      ],
      "metadata": {
        "id": "c0R2FJ8l9zoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"author\").agg(\n",
        "    F.count(\"*\").alias(\"total_articles\"),\n",
        "    F.countDistinct(\"source\").alias(\"unique_sources\"),\n",
        "    F.first(\"date\").alias(\"first_article_date\"),\n",
        "    F.last(\"date\").alias(\"last_article_date\")\n",
        ").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDoI5K9N92bU",
        "outputId": "c6c62eb9-1ef2-413e-800a-b9eea150258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------+--------------+--------------------+-------------------+\n",
            "|       author|total_articles|unique_sources|  first_article_date|  last_article_date|\n",
            "+-------------+--------------+--------------+--------------------+-------------------+\n",
            "| Aarón Torres|            12|             2|      March 30, 2023|     March 20, 2023|\n",
            "| Alan Hovorka|             4|             1|     August 12, 2022|    August 12, 2022|\n",
            "| Alexis Waiss|            16|             3|    October 18, 2022|   November 2, 2022|\n",
            "|Amanda Boring|             4|             1|    October 18, 2022|   October 18, 2022|\n",
            "|  Amy Sherman|           216|            28| a total mess. Th...| September 30, 2022|\n",
            "|  Andy Nguyen|           268|            11| employee passed ...|     August 1, 2022|\n",
            "|    Ben Wells|             4|             1|    October 31, 2022|   October 31, 2022|\n",
            "| Blake Farmer|             4|             1| America First Legal|America First Legal|\n",
            "| Cameron Carr|            16|             4|       March 8, 2023|     March 29, 2023|\n",
            "| Chad Bradley|            12|             3|    November 4, 2022|   October 17, 2022|\n",
            "+-------------+--------------+--------------+--------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using SQL functions with .select()"
      ],
      "metadata": {
        "id": "EzjUiNyA-HwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\n",
        "    F.count(\"*\").alias(\"total_rows\"),\n",
        "    F.countDistinct(\"author\").alias(\"unique_authors\")\n",
        ").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgtYBPHr-NoE",
        "outputId": "4ae1e3cb-c7aa-4a14-c8e5-5face382be1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+\n",
            "|total_rows|unique_authors|\n",
            "+----------+--------------+\n",
            "|      6000|            71|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Register as SQL table and run SQL-style aggregation"
      ],
      "metadata": {
        "id": "mLDXZNSz-c6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"mydata\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT author, COUNT(*) AS article_count\n",
        "    FROM mydata\n",
        "    GROUP BY author\n",
        "    ORDER BY article_count DESC\n",
        "    LIMIT 10\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcadpqdI-gE1",
        "outputId": "3b1b31de-bf22-4e14-cc6f-45a52e6361fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|           author|article_count|\n",
            "+-----------------+-------------+\n",
            "|   Ciara O'Rourke|         1732|\n",
            "|     Jeff Cercone|          372|\n",
            "|Gabrielle Settles|          340|\n",
            "|    Tom Kertscher|          304|\n",
            "|   Madison Czopek|          280|\n",
            "|      Andy Nguyen|          268|\n",
            "|   Louis Jacobson|          240|\n",
            "|  Loreben Tuquero|          228|\n",
            "|      Amy Sherman|          216|\n",
            "|       Sara Swann|          196|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
        "\n",
        "# Load CSV\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkjdUo9oA2jF",
        "outputId": "2767d01b-dfb2-4de6-a560-62106f96739a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Unnamed: 0: long (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            " |-- statement: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- target: string (nullable = true)\n",
            " |-- BinaryTarget: string (nullable = true)\n",
            " |-- BinaryNumTarget: long (nullable = true)\n",
            " |-- Fake: string (nullable = true)\n",
            " |-- Real: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Example: create binary label (1 if True, 0 if False)\n",
        "df = df.withColumn(\"label\", when(df[\"BinaryTarget\"] == \"REAL\", 1).otherwise(0))"
      ],
      "metadata": {
        "id": "O8GF4DyTA8xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itt5WIFjBF76",
        "outputId": "aa79ed51-fc05-46b0-8468-0821a3677064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+-----+\n",
            "|Unnamed: 0|          author|           statement|         source|         date|     target|BinaryTarget|BinaryNumTarget|Fake|Real|label|\n",
            "+----------+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+-----+\n",
            "|         0|Marta Campabadal|“Netflix estrenó ...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|    0|\n",
            "|         1|  Louis Jacobson|Says that under h...|      Joe Biden|June 29, 2023|mostly-true|        REAL|              1|NULL|REAL|    1|\n",
            "|         2|    Jeff Cercone|\"\"\"ONU ordena des...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|    0|\n",
            "|         3|      Sara Swann|NASA warns of “in...| Facebook posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|    0|\n",
            "|         4|    Jeff Cercone|Video suggests CO...|Instagram posts|June 29, 2023|      FALSE|        FAKE|              0|FAKE|NULL|    0|\n",
            "+----------+----------------+--------------------+---------------+-------------+-----------+------------+---------------+----+----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "\n",
        "# Convert categorical text into numeric indexes\n",
        "author_indexer = StringIndexer(inputCol=\"author\", outputCol=\"author_index\")\n",
        "source_indexer = StringIndexer(inputCol=\"source\", outputCol=\"source_index\")\n",
        "\n",
        "# Assemble features into one vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"author_index\", \"source_index\"],  # add more numeric features if available\n",
        "    outputCol=\"features\"\n",
        ")"
      ],
      "metadata": {
        "id": "nCEZOeIYBUm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "6zNFsUVtBZtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Build pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=[author_indexer, source_indexer, assembler, lr])\n",
        "\n",
        "# Train model\n",
        "model = pipeline.fit(train_data)\n"
      ],
      "metadata": {
        "id": "KDrqQeKqBcRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"Author\", \"Source\", \"label\", \"prediction\", \"probability\").show(10)\n",
        "\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\")\n",
        "print(\"Test AUC:\", evaluator.evaluate(predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOusQTMMBh2x",
        "outputId": "2794f691-7feb-4404-a18e-35c560a584ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+-----+----------+--------------------+\n",
            "|              Author|         Source|label|prediction|         probability|\n",
            "+--------------------+---------------+-----+----------+--------------------+\n",
            "|        Jeff Cercone| Facebook posts|    0|       0.0|[0.94604377444286...|\n",
            "|       Tom Kertscher| Facebook posts|    0|       0.0|[0.93984929247315...|\n",
            "|Sofia Bliss-Carra...|Vivek Ramaswamy|    1|       0.0|[0.54531579949987...|\n",
            "|    Marta Campabadal| Facebook posts|    0|       0.0|[0.89235204140892...|\n",
            "|       Tom Kertscher|Instagram posts|    0|       0.0|[0.93946411269795...|\n",
            "|       Tom Kertscher|Instagram posts|    0|       0.0|[0.93946411269795...|\n",
            "|Sofia Bliss-Carra...|      Joe Biden|    0|       0.0|[0.66775216157029...|\n",
            "|      Ciara O'Rourke| Facebook posts|    0|       0.0|[0.94891074186131...|\n",
            "|       Tom Kertscher| Facebook posts|    0|       0.0|[0.93984929247315...|\n",
            "|       Maria Briceño| Facebook posts|    0|       0.0|[0.88669017492780...|\n",
            "+--------------------+---------------+-----+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Test AUC: 0.8225312465587492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF–IDF Approach (Term Frequency – Inverse Document Frequency)\n",
        "#TF–IDF gives you a vector representation of text based on word importance.\n",
        "\n",
        "#Steps:\n",
        "##Tokenize — split \"Statement\" into words.\n",
        "\n",
        "##Remove stopwords — drop common words like “the”, “is”, “and”.\n",
        "\n",
        "##HashingTF — map words to term frequency vectors.\n",
        "\n",
        "##IDF — scale term frequencies by importance across the corpus.\n",
        "\n",
        "##Assemble features — combine TF–IDF vector with any other numeric features.\n",
        "\n",
        "##Train Logistic Regression"
      ],
      "metadata": {
        "id": "v6HksSYrCdQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(df.statement.isNotNull())\n",
        "df = df.filter(df.statement != \"\")"
      ],
      "metadata": {
        "id": "jsQPvGG0DpcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(df.BinaryTarget.isNotNull())\n",
        "\n",
        "# Check distinct classes\n",
        "df.select(\"BinaryTarget\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgGjnDUoDvGT",
        "outputId": "7bf47d66-3c8b-4c9c-c336-8b9fb1770a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|        BinaryTarget|\n",
            "+--------------------+\n",
            "|               FALSE|\n",
            "|        DUI offenses|\n",
            "|      March 20, 2023|\n",
            "|     Instagram posts|\n",
            "|    October 25, 2022|\n",
            "|                FAKE|\n",
            "|    November 3, 2022|\n",
            "|                TRUE|\n",
            "|    November 2, 2022|\n",
            "|    October 12, 2022|\n",
            "|        May 26, 2023|\n",
            "|      March 17, 2023|\n",
            "|     August 18, 2022|\n",
            "|          pants-fire|\n",
            "|    November 4, 2022|\n",
            "|      Facebook posts|\n",
            "|     August 26, 2022|\n",
            "|           half-true|\n",
            "|       July 29, 2022|\n",
            "|American Leadersh...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# 1️⃣ Start Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FakeNews_TFIDF_LR\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# 2️⃣ Load CSV\n",
        "df = spark.createDataFrame(pdf)\n",
        "\n",
        "# 3️⃣ Keep only needed columns\n",
        "# Adjust column names if your CSV is different\n",
        "df = df.select(\"statement\", \"BinaryTarget\")\n",
        "\n",
        "# 4️⃣ Clean Data - Remove nulls & empty text\n",
        "df = df.filter(col(\"statement\").isNotNull())\n",
        "df = df.filter(col(\"statement\") != \"\")\n",
        "df = df.filter(col(\"BinaryTarget\").isNotNull())\n",
        "\n",
        "# 5️⃣ Create binary label column\n",
        "# Example: TRUE → 1, FALSE → 0\n",
        "df = df.withColumn(\"label\", when(col(\"BinaryTarget\") == \"REAL\", 1).otherwise(0))\n",
        "\n",
        "# 6️⃣ Tokenize, Remove Stopwords, Apply TF–IDF\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"statement\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "\n",
        "# 7️⃣ Logistic Regression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# 8️⃣ Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
        "\n",
        "# 9️⃣ Train/Test Split — Ensure both have at least 2 classes\n",
        "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Check class counts\n",
        "train_labels = train.select(\"label\").distinct().count()\n",
        "test_labels = test.select(\"label\").distinct().count()\n",
        "\n",
        "if train_labels < 2 or test_labels < 2:\n",
        "    raise ValueError(\"Train/Test split does not contain both label classes. Adjust split or data.\")\n",
        "\n",
        "# 🔟 Train model\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# 1️⃣1️⃣ Predictions\n",
        "predictions = model.transform(test)\n",
        "predictions.select(\"Statement\", \"label\", \"prediction\", \"probability\").show(10, truncate=50)\n",
        "\n",
        "# 1️⃣2️⃣ Evaluation\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\")\n",
        "\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(\"Test AUC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "QGsQK-VbEFJb",
        "outputId": "5eec5d93-0aa2-430f-c3e8-0538cae00e77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2048584788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# 🔟 Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# 1️⃣1️⃣ Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if any statement appears in both train and test\n",
        "train_statements = set([row.statement for row in train.collect()])\n",
        "test_statements = set([row.statement for row in test.collect()])\n",
        "overlap = train_statements.intersection(test_statements)\n",
        "print(f\"Overlap count: {len(overlap)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XltWrXPsCmur",
        "outputId": "f6be7faf-99c6-4485-f5d4-aead50f988db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap count: 870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove exact duplicates based on 'Statement'\n",
        "df_clean = df.dropDuplicates([\"statement\"])\n",
        "\n",
        "# Now split into train/test without leakage\n",
        "train, test = df_clean.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "DtPta0fJFdZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "cv = CrossValidator(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=ParamGridBuilder().build(),\n",
        "    evaluator=BinaryClassificationEvaluator(),\n",
        "    numFolds=5\n",
        ")\n",
        "\n",
        "cvModel = cv.fit(df_clean)"
      ],
      "metadata": {
        "id": "Z1r6PeUoFhna",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9b5a2aa3-0d36-4d4a-dffd-a4de2b139a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3227552649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             )\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mmetrics_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# -------------------\n",
        "# 1. Start Spark Session\n",
        "# -------------------\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LogisticRegressionTFIDF_Binary\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# -------------------\n",
        "# 2. Load Data\n",
        "# -------------------\n",
        "df = spark.read.csv(\"merged_final.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# -------------------\n",
        "# 3. Ensure Binary Labels\n",
        "# -------------------\n",
        "# Keep only rows where BinaryTarget is 0, 1, True, or False\n",
        "df_clean = df.filter(col(\"BinaryTarget\").isin(0, 1, \"0\", \"1\", \"REAL\", \"FAKE\"))\n",
        "\n",
        "# Drop duplicates on text column to avoid leakage\n",
        "df_clean = df_clean.dropDuplicates([\"statement\"])\n",
        "\n",
        "# -------------------\n",
        "# 4. Prepare ML Pipeline\n",
        "# -------------------\n",
        "# Convert label to numeric (0 or 1)\n",
        "label_indexer = StringIndexer(inputCol=\"BinaryTarget\", outputCol=\"label\")\n",
        "\n",
        "# Tokenize text\n",
        "tokenizer = Tokenizer(inputCol=\"statement\", outputCol=\"words\")\n",
        "\n",
        "# Remove stop words\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "\n",
        "# Term Frequency\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=5000)\n",
        "\n",
        "# Inverse Document Frequency\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "\n",
        "# Logistic Regression (binary)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=20, regParam=0.01)\n",
        "\n",
        "# Full pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, remover, hashingTF, idf, lr])\n",
        "\n",
        "# -------------------\n",
        "# 5. Train-Test Split\n",
        "# -------------------\n",
        "train, test = df_clean.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# -------------------\n",
        "# 6. Train Model\n",
        "# -------------------\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "# -------------------\n",
        "# 7. Predictions\n",
        "# -------------------\n",
        "predictions = model.transform(test)\n",
        "\n",
        "# -------------------\n",
        "# 8. Evaluation\n",
        "# -------------------\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "predictions.select(\"statement\", \"BinaryTarget\", \"prediction\", \"probability\").show(10, truncate=True)\n",
        "print(f\"Test AUC: {auc:.3f}\")\n"
      ],
      "metadata": {
        "id": "2sASqUwZMnqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PySpark Assignment: Loan Data Analysis\n",
        "#Dataset: loan.csv (contains loan applications with customer details, loan amount, purpose, and status)\n",
        "\n",
        "[Loan Dataset](https://github.com/makhan010385/DataBricks-/blob/main/loan.csv)\n",
        "\n",
        "\n",
        "#Objective:\n",
        "##We will use PySpark to load, process, and analyze the loan dataset, applying DataFrame operations, Spark SQL, and Machine Learning concepts.\n",
        "\n",
        "##Part 1 — Data Loading & Exploration\n",
        "###Start a SparkSession in PySpark.\n",
        "\n",
        "###Load loan.csv into a PySpark DataFrame with headers.\n",
        "\n",
        "###Display the first 10 rows of the dataset.\n",
        "\n",
        "###Show the schema of the DataFrame.\n",
        "\n",
        "###Count the total number of records.\n",
        "\n",
        "##Part 2 — Data Cleaning\n",
        "###Remove duplicate rows.\n",
        "\n",
        "####Handle missing values:\n",
        "\n",
        "###Drop rows with missing loan_status or loan_amnt.\n",
        "\n",
        "###Convert numeric columns to the correct data types (e.g., loan_amnt to integer).\n",
        "\n",
        "##Part 3 — Data Analysis\n",
        "###Find the average loan amount for each loan purpose.\n",
        "\n",
        "###Count how many loans were Fully Paid vs Charged Off.\n",
        "\n",
        "###Find the top 5 loan purposes by average funded amount.\n",
        "\n",
        "##Part 4 — Spark SQL\n",
        "###Register the DataFrame as a temporary SQL view.\n",
        "\n",
        "###Using Spark SQL:\n",
        "\n",
        "###Get the loan purpose with the highest default rate.\n",
        "\n",
        "###Find the state with the most charged-off loans.\n",
        "\n",
        "##Part 5 — Machine Learning (Optional)\n",
        "###Use StringIndexer to encode categorical columns like purpose and loan_status.\n",
        "\n",
        "###Use VectorAssembler to combine features.\n",
        "\n",
        "###Train a Logistic Regression model to predict loan_status (binary classification: Fully Paid vs Charged Off).\n",
        "\n",
        "###Evaluate model accuracy."
      ],
      "metadata": {
        "id": "rKebYjFXQ6Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1 Solution ( Data Loading & Exploration )**\n",
        "Start a SparkSession in PySpark.\n",
        "Load loan.csv into a PySpark DataFrame with headers.\n",
        "Display the first 10 rows of the dataset.\n",
        "Show the schema of the DataFrame.\n",
        "Count the total number of records.\n"
      ],
      "metadata": {
        "id": "k2vQm7KgMY_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LocalSparkExample\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 1: Use RAW GitHub CSV link\n",
        "url = \"https://raw.githubusercontent.com/makhan010385/DataBricks-/refs/heads/main/loan.csv\"\n",
        "\n",
        "# Step 2: Load CSV into Pandas DataFrame\n",
        "pdf = pd.read_csv(url)\n",
        "\n",
        "# Step 3: Convert Pandas → Spark DataFrame\n",
        "df = spark.createDataFrame(pdf)\n",
        "\n",
        "# Step 4: Show results\n",
        "df.show(10)\n",
        "df.printSchema()\n",
        "df.count()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb9bG7JZM8k7",
        "outputId": "3a040657-1e1d-4d2e-dd64-2e3c5ac6fde1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+------+-----------------+--------------+-----------+-------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n",
            "|Customer_ID|Age|Gender|       Occupation|Marital Status|Family Size| Income|Expenditure|Use Frequency|Loan Category|Loan Amount|Overdue| Debt Record| Returned Cheque| Dishonour of Bill|\n",
            "+-----------+---+------+-----------------+--------------+-----------+-------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n",
            "|    IB14001| 30|  MALE|     BANK MANAGER|        SINGLE|          4|50000.0|    22199.0|            6|      HOUSING| 10,00,000 |      5|      42,898|               6|                 9|\n",
            "|    IB14008| 44|  MALE|        PROFESSOR|       MARRIED|          6|51000.0|    19999.0|            4|     SHOPPING|     50,000|      3|      33,999|               1|                 5|\n",
            "|    IB14012| 30|FEMALE|          DENTIST|        SINGLE|          3|58450.0|    27675.0|            5|   TRAVELLING|     75,000|      6|      20,876|               3|                 1|\n",
            "|    IB14018| 29|  MALE|          TEACHER|       MARRIED|          5|45767.0|    12787.0|            3|    GOLD LOAN|  6,00,000 |      7|      11,000|               0|                 4|\n",
            "|    IB14022| 34|  MALE|           POLICE|        SINGLE|          4|43521.0|    11999.0|            3|   AUTOMOBILE|  2,00,000 |      2|      43,898|               1|                 2|\n",
            "|    IB14024| 55|FEMALE|            NURSE|       MARRIED|          6|34999.0|    19888.0|            4|   AUTOMOBILE|     47,787|      1|      50,000|               0|                 3|\n",
            "|    IB14025| 39|FEMALE|          TEACHER|       MARRIED|          6|46619.0|    18675.0|            4|      HOUSING| 12,09,867 |      8|      29,999|               6|                 8|\n",
            "|    IB14027| 51|  MALE|   SYSTEM MANAGER|       MARRIED|          3|49999.0|    19111.0|            5|  RESTAURANTS|     60,676|      8|      13,000|               2|                 5|\n",
            "|    IB14029| 24|FEMALE|          TEACHER|        SINGLE|          3|45008.0|    17454.0|            4|   AUTOMOBILE|  3,99,435 |      9|      51,987|               4|                 7|\n",
            "|    IB14031| 37|FEMALE|SOFTWARE ENGINEER|       MARRIED|          5|55999.0|    23999.0|            5|   AUTOMOBILE|     60,999|      2|           0|               5|                 3|\n",
            "+-----------+---+------+-----------------+--------------+-----------+-------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "root\n",
            " |-- Customer_ID: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Occupation: string (nullable = true)\n",
            " |-- Marital Status: string (nullable = true)\n",
            " |-- Family Size: long (nullable = true)\n",
            " |-- Income: double (nullable = true)\n",
            " |-- Expenditure: double (nullable = true)\n",
            " |-- Use Frequency: long (nullable = true)\n",
            " |-- Loan Category: string (nullable = true)\n",
            " |-- Loan Amount: string (nullable = true)\n",
            " |-- Overdue: long (nullable = true)\n",
            " |--  Debt Record: string (nullable = true)\n",
            " |--  Returned Cheque: long (nullable = true)\n",
            " |--  Dishonour of Bill: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2 Solution (Data Cleaning)**\n",
        "Remove duplicate rows.\n",
        "Handle missing values:\n",
        "Drop rows with missing loan_status or loan_amnt.\n",
        "Convert numeric columns to the correct data types (e.g., loan_amnt to integer).\n"
      ],
      "metadata": {
        "id": "ylUF46dLMuub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropDuplicates()\n",
        "df = df.dropna(subset=[\"loan Amount\"])\n",
        "df = df.withColumn(\"loan Amount\", df[\"loan Amount\"].cast(\"integer\"))\n",
        "df.show(10)\n",
        "df.printSchema()\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_FCvN_M9jT",
        "outputId": "6afc099b-c426-4235-d239-39b8099a8a2e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+------+-----------------+--------------+-----------+-------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n",
            "|Customer_ID|Age|Gender|       Occupation|Marital Status|Family Size| Income|Expenditure|Use Frequency|Loan Category|loan Amount|Overdue| Debt Record| Returned Cheque| Dishonour of Bill|\n",
            "+-----------+---+------+-----------------+--------------+-----------+-------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n",
            "|    IB14001| 30|  MALE|     BANK MANAGER|        SINGLE|          4|50000.0|    22199.0|            6|      HOUSING|       NULL|      5|      42,898|               6|                 9|\n",
            "|    IB14008| 44|  MALE|        PROFESSOR|       MARRIED|          6|51000.0|    19999.0|            4|     SHOPPING|       NULL|      3|      33,999|               1|                 5|\n",
            "|    IB14012| 30|FEMALE|          DENTIST|        SINGLE|          3|58450.0|    27675.0|            5|   TRAVELLING|       NULL|      6|      20,876|               3|                 1|\n",
            "|    IB14018| 29|  MALE|          TEACHER|       MARRIED|          5|45767.0|    12787.0|            3|    GOLD LOAN|       NULL|      7|      11,000|               0|                 4|\n",
            "|    IB14022| 34|  MALE|           POLICE|        SINGLE|          4|43521.0|    11999.0|            3|   AUTOMOBILE|       NULL|      2|      43,898|               1|                 2|\n",
            "|    IB14024| 55|FEMALE|            NURSE|       MARRIED|          6|34999.0|    19888.0|            4|   AUTOMOBILE|       NULL|      1|      50,000|               0|                 3|\n",
            "|    IB14025| 39|FEMALE|          TEACHER|       MARRIED|          6|46619.0|    18675.0|            4|      HOUSING|       NULL|      8|      29,999|               6|                 8|\n",
            "|    IB14027| 51|  MALE|   SYSTEM MANAGER|       MARRIED|          3|49999.0|    19111.0|            5|  RESTAURANTS|       NULL|      8|      13,000|               2|                 5|\n",
            "|    IB14029| 24|FEMALE|          TEACHER|        SINGLE|          3|45008.0|    17454.0|            4|   AUTOMOBILE|       NULL|      9|      51,987|               4|                 7|\n",
            "|    IB14031| 37|FEMALE|SOFTWARE ENGINEER|       MARRIED|          5|55999.0|    23999.0|            5|   AUTOMOBILE|       NULL|      2|           0|               5|                 3|\n",
            "+-----------+---+------+-----------------+--------------+-----------+-------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "root\n",
            " |-- Customer_ID: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Occupation: string (nullable = true)\n",
            " |-- Marital Status: string (nullable = true)\n",
            " |-- Family Size: long (nullable = true)\n",
            " |-- Income: double (nullable = true)\n",
            " |-- Expenditure: double (nullable = true)\n",
            " |-- Use Frequency: long (nullable = true)\n",
            " |-- Loan Category: string (nullable = true)\n",
            " |-- loan Amount: integer (nullable = true)\n",
            " |-- Overdue: long (nullable = true)\n",
            " |--  Debt Record: string (nullable = true)\n",
            " |--  Returned Cheque: long (nullable = true)\n",
            " |--  Dishonour of Bill: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 3 Solution (Data Analysis)**\n",
        "Find the average loan amount for each loan purpose.\n",
        "Count how many loans were Fully Paid vs Charged Off.\n",
        "Find the top 5 loan purposes by average funded amount.\n"
      ],
      "metadata": {
        "id": "wQU3y3YGMvJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"loan Category\").agg({\"loan Amount\": \"avg\"}).show()\n",
        "df.groupBy(\"loan Category\").agg({\"loan Amount\": \"avg\"}).orderBy(\"avg(loan Amount)\", ascending=False).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr4Xq4SJM-px",
        "outputId": "1123f49e-853e-4ffc-8b1a-2de4cc9e6829"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------------+\n",
            "|     loan Category|avg(loan Amount)|\n",
            "+------------------+----------------+\n",
            "|           HOUSING|            NULL|\n",
            "|        TRAVELLING|            NULL|\n",
            "|       BOOK STORES|            NULL|\n",
            "|         GOLD LOAN|            NULL|\n",
            "|  EDUCATIONAL LOAN|            NULL|\n",
            "|        AUTOMOBILE|            NULL|\n",
            "|COMPUTER SOFTWARES|            NULL|\n",
            "|           DINNING|            NULL|\n",
            "|          SHOPPING|            NULL|\n",
            "|       RESTAURANTS|            NULL|\n",
            "|       ELECTRONICS|            NULL|\n",
            "|          BUILDING|            NULL|\n",
            "|   HOME APPLIANCES|            NULL|\n",
            "|       AGRICULTURE|            NULL|\n",
            "|          BUSINESS|            NULL|\n",
            "|        RESTAURANT|            NULL|\n",
            "+------------------+----------------+\n",
            "\n",
            "+----------------+----------------+\n",
            "|   loan Category|avg(loan Amount)|\n",
            "+----------------+----------------+\n",
            "|         HOUSING|            NULL|\n",
            "|      TRAVELLING|            NULL|\n",
            "|     BOOK STORES|            NULL|\n",
            "|       GOLD LOAN|            NULL|\n",
            "|EDUCATIONAL LOAN|            NULL|\n",
            "+----------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 4 Solution ( Spark SQL)**\n",
        "Register the DataFrame as a temporary SQL view.\n",
        "Using Spark SQL:\n",
        "Get the loan purpose with the highest default rate.\n",
        "Find the state with the most charged-off loans."
      ],
      "metadata": {
        "id": "2ZhFRjZwMvde"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zr48i1bXM_xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 5 Solution Machine Learning (Optional)**\n",
        "\n",
        "Use StringIndexer to encode categorical columns like purpose and loan_status.\n",
        "Use VectorAssembler to combine features.\n",
        "Train a Logistic Regression model to predict loan_status (binary classification: Fully Paid vs Charged Off).\n",
        "Evaluate model accuracy.\n"
      ],
      "metadata": {
        "id": "zNyi1WwyMvwk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04O5Ib2fRSj9"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}